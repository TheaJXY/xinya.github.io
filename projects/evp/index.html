<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Audio-Driven Emotional Video Portraits</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Audio-Driven Emotional Video Portraits." />
	<meta property="og:description" content="Webpage of EVP algorithm." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Audio-Driven Emotional Video Portraits</span>
		<table align=center width=600px>
			<br> </br>
			<table align=center width=600px>
				<tr>
					<td align=center width=150px>
						<center>
							<span style="font-size:18px"><a href="https://jixinya.github.io/projects/evp/">Xinya Ji</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:18px"><a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:18px"><a href="https://jixinya.github.io/projects/evp/">Kaisiyuan Wang</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:18px"><a href="https://jixinya.github.io/projects/evp/">Wayne Wu</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=600px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://personal.ie.cuhk.edu.hk/~ccloy/">Chen Change Loy</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://xufeng.site/">Feng Xu</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=700px>
				<tr>
					<td align=center width=170px>
						<center>
							<span style="font-size:16px">Nanjing University</span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:16px">The Chinese University of Hong Kong</span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:16px">The University of Sydney</span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=700px>
				<tr>
					<td align=center width=170px>
						<center>
							<span style="font-size:16px">SenseTime Research</span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:16px">Nanyang Technological University</span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:16px">Tsinghua University</span>
						</center>
					</td>
				</tr>
			</table>
			&nbsp;
			<table align=center width=200px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">CVPR 2021</span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:18px"><a href='./resources/evp.pdf'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:18px"><a href='https://jixinya.github.io/projects/evp/'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:750px" src="./resources/Fig1.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					<span style="font-size:15px">Given an audio clip and a target video, our Emotional Video Portraits (EVP)
					approach is capable of generating emotion-controllable talking portraits and change the emotion of them smoothly by interpolating at
					the latent space.</span>.
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=900px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				In this work, we present Emotional Video Portraits (EVP), a system for synthesizing high-quality video portraits with vivid emotional dynamics driven by audios. Specifically, we
				propose the Cross-Reconstructed Emotion Disentanglement
				technique to decompose speech into two decoupled spaces,
				i.e., a duration-independent emotion space and a duration dependent content space. With the disentangled features,
				dynamic 2D emotional facial landmarks can be deduced.
				Then we propose the Target-Adaptive Face Synthesis technique to generate the final high-quality video portraits, by
                bridging the gap between the deduced landmarks and the
				natural head poses of target videos. Extensive experiments
				demonstrate the effectiveness of our method both qualitatively and quantitatively.
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<center><h1>Video</h1></center>
	
	<p align="center">
		<iframe width="660" height="395" src="./resources/00822-video.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
		<!-- Video player 1422x800 
		<video width="660" height="395" controls autoplay>
		  <source src="./resources/00822-video.mp4" type="video/mp4">							  
		Your browser does not support the video tag.
		</video>-->
	</p>


	<hr>

	<center><h1>Code</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:800px" src="./resources/pipeline.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<center>
					Overview of our Emotional Video Portrait algorithm.
				</center>
			</tr>
		</center>
	</table>
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:20px">&nbsp;<a href='https://jixinya.github.io/projects/evp/'>[GitHub]</a>
			</center>
		</span>
	</table>
	<br>
	<hr>
	<table align=center width=650px>
		<center><h1>Paper</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/evp_1.png"/></a></td>
			<td><span style="font-size:14pt"><b>Audio-Driven Emotional Video Portraits.</b><br>
				In CVPR, 2021.<br>
				(hosted on <a href="">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:15pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This work is supported partly by the
					NSFC (No.62025108), the National Key R&D Program
					of China 2018YFA0704000, partly by the Beijing Natural
					Science Foundation (JQ19015), the NSFC (No.61822111,
					61727808, 61627804), the NSFJS (BK20192003), partly
					by Leading Technology of Jiangsu Basic Research Plan under Grant BK2019200, and partly by A*STAR through the
					Industry Alignment Fund - Industry Collaboration Projects
					Grant..
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

